# Sarvam Litmus Test: Build a Scalable LLM Chatbot System

## Overview
Design and implement a chat application powered by a Large Language Model (e.g., OpenAI, Anthropic, Llama, etc.) that can support 10,000+ users. Your solution should demonstrate your approach to building production-ready systems.

## Requirements

### Core Functionality
- Create a chat interface where users can have conversations with an LLM
- Maintain conversation history for context
- Support at least 10,000 users

### Technical Focus Areas
1. **System Architecture**
   - Design an appropriate architecture (provide a diagram)
   - Explain your choice of components and how they interact

2. **Scalability**
   - Describe how your system handles increased load
   - Explain how your infrastructure will scale to support 10,000 users
   - Address potential bottlenecks in your design
   - Explain your strategy for horizontal and vertical scaling

3. **Reliability**
   - Consider how your system handles failures
   - Explain your approach to maintaining service quality

4. **Cost Considerations**
   - Explain your approach to managing operational costs
   - Address efficiency considerations for an LLM-based system

5. **ML/AI Integration**
   - Explain your LLM integration strategy
   - Describe your approach to context management and prompt engineering
   - Detail any advanced techniques like RAG, fine-tuning, or few-shot learning
   - Address model performance optimization and latency considerations
   - Explain your approach to evaluating and improving response quality
   - Detail your strategy for handling model failures and fallbacks

## Deliverables
1. Working code repository with documentation
2. System architecture diagram
3. README explaining:
   - Your overall approach and design philosophy
   - How your system handles the required scale
   - Key technical decisions and their justification
4. Deployment instructions or a demo environment

## Evaluation Criteria
You will be evaluated primarily based on your area of interest:

### Backend/Systems Focus
- System architecture and scalability design
- Infrastructure choices and implementation
- API design and documentation for frontend integration
- Performance optimization strategies
- Backend code quality and organization
- Deployment architecture (containerization, orchestration)
- Error handling and monitoring solutions
- Documentation clarity and completeness

### Frontend Focus
- UI/UX design and implementation
- Frontend architecture decisions
- Component design and reusability
- Client-side performance optimization
- Frontend code quality and organization
- API integration and state management
- Error handling and user feedback
- Documentation clarity and completeness

### Full Stack Focus
- End-to-end system implementation
- Balance between frontend and backend concerns
- Full system integration approach
- Overall architecture decisions
- Code quality across the stack
- Deployment pipeline and DevOps considerations
- System monitoring and observability
- Documentation clarity and completeness

### ML/AI Focus

- LLM integration and optimization strategies
- Advanced techniques like RAG (Retrieval-Augmented Generation), fine-tuning, or prompt engineering
- Context handling and semantic search implementation
- Evaluation metrics and performance benchmarks for LLM outputs
- Novel approaches to improve response quality or reduce hallucinations
- ML pipeline design and implementation
- Basic frontend and backend implementation to showcase ML capabilities
- Documentation of ML system design decisions

Please specify your preferred role (Backend/Frontend/Full Stack) in your submission. We will evaluate your solution with emphasis on the corresponding criteria while maintaining a holistic view of your implementation.

### Bonus Points
- Innovation beyond basic LLM integration (e.g., custom prompt engineering, output formatting)
- Implementation of advanced features like:
  - Streaming responses
  - Custom model fine-tuning
  - Hybrid approaches combining multiple models
  - Novel UI/UX patterns for chat interactions
  - Intelligent caching strategies
  - Advanced context management
  - Multi-modal capabilities (text + images)
  - Knowledge base integration with efficient vector search
  - Few-shot or zero-shot adaptation techniques

## Time Expectation
Please complete this challenge within 7 days. We're looking for quality of thinking rather quantity of features.

## Submission
Please email your solution as a Git repository link with all required documentation at nitesh@sarvam.ai.